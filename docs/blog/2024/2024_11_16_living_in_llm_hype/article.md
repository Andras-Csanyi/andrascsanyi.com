---
title: Living in the LLM hype
---

> [!NOTE]
> This is the strong draft version of an article published on X with the
> [Living in the LLM hype](https://x.com/csanyi_andras/status/1858136157504016666)
> title. If you like this content please read the article on X it
> shows your support to continue writing articles like this. Thank you!

I am totally fed up with the AI bros warmongering, world ending and fatalist
attitude!
It is just endlessly stupid and many times I have the feeling they don't even
think just repeat the marketing stupidity they hear.
As a balance I am writing down clearly what I am going to do and why.

![art tweet](images/art_tweet.png)

The whole is about LLMs and not what AI can do in video and music, or even
Tesla's FSD. These are different stories and don't impact me directly.

I am going to strengthen my knowledge and practice by doing many different
things.
I am a builder, I like to build small things to either better understand
them or put different things into a context and experiencing how they impact and
reform each other.
For me who is looking for "what can I learn from this" moments this is source
of satisfaction, usable knowledge and fun.
From AI Bros point of view this sounds just a looser attitude.
Why would you do this since an LLM can give you all of this?
Have you ever done competition sport?
Those girls and boys remain competitive because they practice.
I was one of them and daily practice is the minimum keeping you on the top.
And doesn't matter how many LLMs you pour on the world LLMs still live on human
produced data and you need human programmers to produce code.

Testing and exercising my knowledge from different directions increases my
versatility and will manifest in better gut feelings.
Gut feeling is mechanical sympathy.
Mastered craft is mechanical sympathy.
This is what you need.
LLM won't help you in this process.

## What does my practicing look like?

The practice part is not Leetcode or any artificially created problem without
zero context.
Leetcode, as it is, just super stupid.
Poorly written exercises focusing on obscure edge-cases and the only thing they
do is gaslighting you hard.
If you need suffering and high level of anxiety go to Leetcode.
What you can do instead is taking out the exercises from Leetcode, identify
their type and gradually, in you own pace, increase their complexity and
difficulty.

What you can do too is building something which is interesting for you, like an
HTTP server, create a minimal MVC framework, create a small programming
language, create your own HTTP client generator, figure out use cases where you
have to provide a piece of software processing a certain input and so on.
Build your own silly, stupid infrastructure and give traffic to it and observe
how it behaves and when it crashes.
Feel free to be creative.
Perfection is not a goal.
Moving by small steps and either including a new functionality or enhancing a
certain part of the code is the goal.
It helps you to see small and easy to implement tasks, develops your ability to
present these and deliver them.

The experience of being able to deliver in you own project will sneak into your
daily job.
For your brain, for your world interpreting cognitive functions there is no
difference between you job and your hobby.
The experiences you go through, and as a matter of fact what you imagine too,
are processed by the same cognitive functions and equally built into how you
behave in the world.
And you can leverage on this phenomena.

Moreover, a daily evaluation of "what did I do today, what was good and what can
I improve?" is the best you can do to yourself.
Or you can drink a coffee.
A coffee is a good thing too.

I like to have periods where I totally disable Intellisense or other code
completion tools.
This forces me to learn more deeply the apis I work with.
My coding speed is less as I have to look up the methods, but my familiarity
with the tools I am using is increasing.
This process is similar to learning a language.
You need raw input, immersion and let your brain figure out things.
Your job is provide exposure.

If you are at doubt whether you can learn the apis to some extent I have a good
news for you.
The more you learn, the more versatile your brain will be.
The more you read, the more versatile your brain will be.
But, do a favour for yourself, don't stress on this just let it happen.

I started learning touch typing and got into the NeoVim world.
This is a more raw experience than what any JetBrains product can give you.
But, the real reason I started this is removing my typing speed as a bottle
neck.
I realised that I type way slower than I think and it frustrates me over time
and frustration reduces cognitive performance.
So, I started working on how can I reduce this and the result is touch typing,
Kinesis keyboard, and NeoVim.

## But the pressure...

Majority of the AI bros don't have a clue what they are talking about.
They are just sitting on the hype train as they don't have anything else.

### GIGO

LLMs are under the Tyranny of GIGO.
GIGO is Garbage-In Garbage-Out, meaning a system cannot produce better
product/information than the provided information.
So far, only humans are capable of overcome this.
LLMs using human produced data to give you the magic.
If the information is bad, the product is bad.
Just see my ranting about how crappy answers I get from Copilot when I ask
certain things.

When the data produced by LLM is fed back as input the model performance shrinks
drastically.
This is the Tyranny of GIGO.

When you take a group of people in a meeting room and give them a problem and
the produced information is fed back as input highly probably they produce a
better information then they had before.
Yes, this is what we call brainstorming.

The implication of the phenomena is that LLMs always require human produced
input.
So, if the programming profession reached its end then who is going to produce
the data for future LLMs?
Are we going to import the small green people from Mars to do so, or what?

### Costs

The other implication is more interesting, there are articles about how the LLM
capabilities are plateaued.
Let me assume that they used all available raw human produced data and used
their best models so far and they reached a plateau.
It seems from this point they have to either specialize the models, or curate
more the dataset or both and all of these means drastically increased cost.
Do you think your 10 USD/monthly subscription will cover this?

From cost point of view we are at the point where the fractional functionality
increase requires more than linear (if I am mean I'll say exponential) resource
needs.
This whole makes financially unsustainable the product.
It means, either further innovation is needed which is an unknown field to me as
I am not in the academia field of LLMs.
The other thing companies can do is finding the segment where the actual
capabilities can produce value, in short specialisation.
At this point, it seems programming is not on the list or if it is on the list
the scope is limited.

### Efficiency

But, everyone sees the generative AI as the future.
Let me dissect it to you.
At current level the generative AIs can provide efficiency in topics where short
and helpful communication is needed like chatbots or some level of customer
service.
This is a great opportunity for a company to increase efficiency and fire
people.
C level folks probably drunk the kool-aid hard and think that this is the
efficiency heaven.
But, they see the efficiency (increased profitability) and not the tool.
In their Excel sheet - driven mindset it doesn't matter if the tool is a
shovel or an LLM model, they just see the "profits are higher" picture.

Take a look at what service LLM can give you and what place this service takes
in your job.

If you are a tutorial jockey you have simple code for your TODO app and
basically the LLM can generate the whole shit for you.
From this point of you this tool is magic and does the job under a minute would
take for you a day.
And you project this and you think... "fuck me... this is magic and I am the
magician here, nothing can stop me."

If you are an indie-developer proudly showing in your X profile what income you
produce and how the 242425234th MR you merged and pushed to production just in
the morning, you are in the situation where you don't work in a team and no
other soul on this amazing planet will read your code.
Your code can be as shit as possible.
Doesn't matter.
Your stuff is running on your own VPS with fixed monthly costs.
It is not cloud where you have to consider all calls and storage implications.
You just rawdog the code and ship the shit to production.

If it takes 5 minutes to prompt out why the `if` goes into the false branch
instead of just understanding how it works and come over the "skill issue" in 20
seconds nobody will see it.
Not even in the coffee place you use as office.
You can still merge and deploy 24234 MRs in the morning and tweet about it in
the afternoon hoping for a Lex Friedman podcast opportunity.
In this case LLM gives you the notion of being productive and the positive or
negative value of the notion depends on how well did you learn prompting the AI
you actually use.
All of them.
Don't be a looser, use at least 3.
All of them in the free tier.
Obviously.

If you are a corporate ant, like me, you are a member of a team and highly
probably working with multiple microservices and medium-high level of technical
debt.
You have your company specific tools and solutions.
Even if you use Kubernetes, Terraform, deployment tools they have their own
company flavour and this knowledge worth nothing outside of the company and the
AI tools don't know or barely know these.
Your code goes through a review process.
The review process, obviously, is not place only for code quality ensuring
activities but power games, meaning the process takes unnecessarily long and the
mental burden is high.
The picture, obviously, not that dire, but the risk of having this dire is there
and occasionally happens and kills your motivation for a while.
The MRs you create are small, a few lines here and there.
These small changes represent the tweaks (lovely patch engineering) the next
feature requires and your domain and system knowledge.
The systems you work with representation of how the company manages the domain
in a profitable way, how it looks for further optimisation and revenue streams
and how the systems are changing are the future plans for the company.
This whole means that if you see a process of "I just add this data here and
click on the save and that's all" it can mean that the single request goes
through 10+ different services and trigger another 10+ processes.
Tell me please how you are going to prompt this problem space for your LLM?
I don't know how to do it.
And If I knew it would take more time to prompt it than making the change by
myself.
This is not the efficiency I am looking for.

Let me fine tune the problem space further.
Writing code is just half of my job.
My job is understanding the systems and making changes how they are connected in
accordance of requirements.
If I translate this to prompting it sounds like hundreds of parameters with
their explanation typed into a search field explaining the context, and that all
parameters are equally important, in order to ask a question, and there is the
risk the LLM decides which one of the parameters are more important than others and
hallucinates a hard for me.
It feels like having a decision discussion with someone who doesn't know shit
about the context.
So, I have to double check the answer.
Fuck, no!

It also includes that evaluation of future feature requests where we check what
impact a feature might have on the current codebase and integration.
This part of the job where LLM doesn't play a role, moreover, if it does it
would be a distraction with its random and randomly sized hallucination.

I see the hope in your eyes and I know that you see chain of small services
where the scope of a single service is not the business domain, but the scope an
LLM can easily manage.
So, the prompting part is optimized.
The least information is needed for the LLM in order to get the most out of it
and the business domain software representation is architected accordingly.
Let me know when you have this one and you can deliver more value with this than
a normal engineering team.

## Using LLMs

I use LLMs as a search engine.
They are excellent when I need to discover a field I don't know yet.
When I don't know what I don't know LLMs can help me to see the important
wordings of the field and how they might be connected.
This is similar to when you open an "Introduction to ..." book and scan through
the table of contents.

If I need specific information they are also good.
Specific means also that I can specify the question well enough to get the
information I need.
In this case LLMs have two strong advantages over simple search engines: 1,
natural language to ask a question, 2, speed and relevancy.

I don't see clearly how can I use LLMs in deepening my knowledge.
This is something I need to discover.
The danger here is the risk of hallucination and the connection between this
risk and the question quality (it is on me).

## Conclusion

Nothing has changed.
You have to master your craft.
You have new tools in this process.
You have to learn using it.
